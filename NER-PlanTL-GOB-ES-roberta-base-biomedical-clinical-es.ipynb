{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a07f9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorForTokenClassification,  RobertaForTokenClassification, RobertaTokenizerFast, pipeline,AutoTokenizer, AutoModelForMaskedLM, EarlyStoppingCallback\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd  \n",
    "from functools import reduce\n",
    "import torch\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import evaluate\n",
    "from evaluate import load  \n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8fcc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained('PlanTL-GOB-ES/roberta-base-biomedical-clinical-es',add_prefix_space=True)\n",
    "tokenizer.model_max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d5c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(path_or_buf=\"HUFA_Corpus.jsonl\", lines=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca98d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entities_to_bio(text, entities):\n",
    "    words = word_tokenize(text)\n",
    "    bio_tags = ['O'] * len(words)\n",
    "    end_char_prev=-1 \n",
    "    cont=0\n",
    "    for entity in entities:\n",
    "        start_char, end_char, entity_type = entity\n",
    "        if start_char>end_char_prev:\n",
    "            end_char_prev=end_char\n",
    "            select=text[start_char:end_char]\n",
    "            tokens=word_tokenize(select)\n",
    "            firstIn=True\n",
    "            \n",
    "            for i in tokens:\n",
    "                I=True\n",
    "                aux=-1\n",
    "                for l in range(cont,len(words)):\n",
    "                    if words[l]==i and firstIn==True and aux<cont:\n",
    "                        bio_tags[l]=f'B-{entity_type}'\n",
    "                        firstIn=False\n",
    "                        cont=l+1\n",
    "                        aux=len(words)\n",
    "                    elif words[l]==i and I==True and aux<cont:\n",
    "                        bio_tags[l]=f'I-{entity_type}'\n",
    "                        cont=l+1\n",
    "                        I=False\n",
    "                        aux=len(words)\n",
    "    return bio_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53538f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances = []\n",
    "tokenized_utterances=[]\n",
    "labels_for_tokens = []\n",
    "for i in df.index:\n",
    "    labels_for_tokens.append(entities_to_bio(df['text'][i], df['label'][i]))\n",
    "    utterances.append(df['text'][i])\n",
    "    tokenized_utterances.append(word_tokenize(df['text'][i])) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd9765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_token_labels = list(set(reduce(lambda x, y: x + y, labels_for_tokens)))\n",
    "labels_for_tokens = [[unique_token_labels.index(_) for _ in l] for l in labels_for_tokens]\n",
    "len(unique_token_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62b56ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.from_dict(\n",
    "    dict(\n",
    "        utterance=utterances,\n",
    "        tokens=tokenized_utterances,\n",
    "        token_labels=labels_for_tokens\n",
    "    )\n",
    ")\n",
    "data = data.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca5a5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -100 is reserved for labels where we do not want to calculate losses.\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    cont=0\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"token_labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i) \n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:  \n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  \n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)  \n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ee05db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_clf_tokenized = data.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3748fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_clf_tokenized['train'] = tok_clf_tokenized['train'].remove_columns(\n",
    "    ['utterance', 'tokens', 'token_labels']\n",
    ")\n",
    "\n",
    "tok_clf_tokenized['test'] = tok_clf_tokenized['test'].remove_columns(\n",
    "    ['utterance', 'tokens', 'token_labels']\n",
    ")\n",
    "\n",
    "tok_clf_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf6cc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10937322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuration to run on GPU\n",
    "'''\n",
    "device = torch.device(\"cpu\")\n",
    "torch.cuda.is_available = lambda: False\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "torch.backends.cudnn.enabled = False'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef59e200",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_clf_model = RobertaForTokenClassification.from_pretrained(\n",
    "    'PlanTL-GOB-ES/roberta-base-biomedical-clinical-es', num_labels=len(unique_token_labels)\n",
    ")\n",
    "tok_clf_model.config.id2label = {i: l for i, l in enumerate(unique_token_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618698ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Model is running on GPU.\")\n",
    "else:\n",
    "    print(\"Model is running on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aea720",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list=labels_for_tokens\n",
    "\n",
    "metric = load(\"seqeval\")\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b249ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directory = f\"Models_Results/PlanTL-GOB-ES-roberta-base-biomedical-clinical-es/\"\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    print(f\"Directory '{directory}' created.\")\n",
    "\n",
    "elements = os.listdir(directory)\n",
    "folders = [element for element in elements if os.path.isdir(os.path.join(directory, element))]\n",
    "folders.sort()\n",
    "\n",
    "index = -1\n",
    "if folders:\n",
    "    last_folder = folders[-1]\n",
    "    index = elements.index(last_folder)\n",
    "    print(f\"The last folder is '{last_folder}' and its index is {index}.\")\n",
    "else:\n",
    "    print(f\"No folders found in '{directory}'. Starting index from 0.\")\n",
    "\n",
    "\n",
    "task = \"NER\"\n",
    "model_checkpoint = \"PlanTL-GOB-ES-roberta-base-biomedical-clinical-es\"\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "file = f\"Models_Results/{model_name}/{model_name}-finetuned-{task}-{index+1}\"\n",
    "\n",
    "print(f\"File path: {file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de757637",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 8\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=file, \n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01, \n",
    "    logging_steps=10,\n",
    "    log_level='info',\n",
    "    evaluation_strategy='epoch', \n",
    "    save_strategy='epoch', \n",
    "    load_best_model_at_end=True,  \n",
    "    metric_for_best_model='f1', \n",
    "    greater_is_better=True,  \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=tok_clf_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tok_clf_tokenized['train'],\n",
    "    eval_dataset=tok_clf_tokenized['test'],\n",
    "    data_collator=tok_data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]  \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7937a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddcc56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eb7d7e-9400-405b-ac92-54d2e45dcfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()\n",
    "tokenizer.save_pretrained(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c75ff1-e472-4f0b-9519-0b97b2a1327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, labels, _ = trainer.predict(tok_clf_tokenized['test'])\n",
    "\n",
    "predicted_labels = np.argmax(predictions, axis=2)\n",
    "\n",
    "true_labels = labels\n",
    "\n",
    "true_labels_flat = []\n",
    "predicted_labels_flat = []\n",
    "\n",
    "for true, pred in zip(true_labels, predicted_labels):\n",
    "    for t, p in zip(true, pred):\n",
    "        if t != -100:\n",
    "            true_labels_flat.append(t)\n",
    "            predicted_labels_flat.append(p)\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(true_labels_flat, predicted_labels_flat, labels=np.arange(len(unique_token_labels)))\n",
    "\n",
    "mask = np.eye(len(unique_token_labels), dtype=bool)\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=unique_token_labels, yticklabels=unique_token_labels, cbar=True, annot_kws={\"size\": 11})\n",
    "\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='coolwarm', mask=~mask, cbar=False, xticklabels=unique_token_labels, yticklabels=unique_token_labels, annot_kws={\"size\": 11})\n",
    "\n",
    "plt.xlabel('Predicted Labels', fontsize=14)\n",
    "plt.ylabel('True Labels', fontsize=14)\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.xticks(rotation=45, ha='right')  \n",
    "plt.yticks(rotation=0)  \n",
    "plt.tight_layout() \n",
    "plt.show()\n",
    "report = classification_report(true_labels_flat, predicted_labels_flat, target_names=unique_token_labels)\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "access2meet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
